name: Immobilien Scraper

on:
  schedule:
    - cron: "*/15 * * * *"  # Alle 15 Minuten
  workflow_dispatch:  # Ermöglicht manuelles Ausführen

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'
      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4
      - name: Download previous results
        run: |
          if [ -f immobilien_count.json ]; then
            echo "JSON file found"
          else
            echo '{"count": null}' > immobilien_count.json  # Fallback, falls kein Artefakt gefunden wurde
      - name: Run Scraper
        env:
          PROWL_API_KEY: ${{ secrets.PROWL_API_KEY }}  # GitHub Secret als Umgebungsvariable
        run: |
          python monitor.py
      - name: Upload results
        uses: actions/upload-artifact@v2
        with:
          name: immobilien-count
          path: immobilien_count.json
